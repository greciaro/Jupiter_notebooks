{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58709f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the current main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rreading the name of the subfolder\n",
    "subfolder_with_path = [f.path for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of files on subfolder\n",
    "list = os.listdir(subfolder_name[1]) \n",
    "number_files = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d707e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the folder\n",
    "os.chdir(subfolder_with_path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a loop to process all files and populate the main data-frame\n",
    "\n",
    "# Starting process timming\n",
    "start = tm.time()\n",
    "\n",
    "# Creating main data-frame\n",
    "df_files_level = [] #This array will contain data frames from each file as elements\n",
    "\n",
    "i = 0\n",
    "while i < number_files:\n",
    "    \n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    # Saving file's name\n",
    "    file = list[i]\n",
    "    \n",
    "    # Reading number and names of sheets\n",
    "    df_full = pd.read_excel(file, sheet_name = None)\n",
    "    sheets_names = df_full.keys()\n",
    "    number_of_sheets = len(sheets_names)\n",
    "    \n",
    "    df_sheets_level = [\" \"]*number_of_sheets #This array will contain data frames from each sheets as elements\n",
    "    \n",
    "    # Reading files\n",
    "    ThreeCT_data = pd.ExcelFile(file)\n",
    "\n",
    "    # Saving session, drug and gender\n",
    "    session_drug_gender = file.split('_')\n",
    "    session = session_drug_gender[0]\n",
    "    drug = session_drug_gender[1]\n",
    "    gender = session_drug_gender[2]\n",
    "\n",
    "\n",
    "    for j in range(0, number_of_sheets):\n",
    "        \n",
    "        ##############################################\n",
    "        # Processing each sheet\n",
    "        ##############################################\n",
    "        \n",
    "        # Reading sheets within files\n",
    "        df_sheets_level[j] = ThreeCT_data.parse(j,header = None)\n",
    "\n",
    "        #Dropping the frist 13 rows and the row between the last reading and the \"sum\"\n",
    "        rows_to_drop = np.arange(13)\n",
    "        df_sheets_level[j] = df_sheets_level[j].drop(df_sheets_level[j].index[rows_to_drop])\n",
    "\n",
    "\n",
    "        #locating empty and iso columns\n",
    "        e = df_sheets_level[j].loc[13].where(df_sheets_level[j].loc[13].str.contains('empty')).dropna(how='all')\n",
    "        e.index #To getthe column value\n",
    "        empty = e.index[0]\n",
    "        s = df_sheets_level[j].loc[13].where(df_sheets_level[j].loc[13].str.contains('iso')).dropna(how='all')\n",
    "        s.index #To getthe column value\n",
    "        iso = s.index[0]\n",
    "\n",
    "        # Categorizing \"duration\" labels wether iso or empty\n",
    "        df_sheets_level[j].iloc[1:2, empty:empty+1] = 'Duration_empty_(s)'\n",
    "        df_sheets_level[j].iloc[1:2, iso:iso+1] = 'Duration_iso_(s)'\n",
    "\n",
    "        #Dropping 13th row, now the 0th row\n",
    "        df_sheets_level[j] =  df_sheets_level[j].drop( df_sheets_level[j].index[0])\n",
    "\n",
    "        #Creating and assigning new header\n",
    "        new_header = df_sheets_level[j].iloc[0] #grab the first row for the header\n",
    "        df_sheets_level[j] = df_sheets_level[j][1:] #take the data less the header row\n",
    "        df_sheets_level[j].columns = new_header #set the header row as the df header\n",
    "        \n",
    "        # Selecting columns of av verlocity and duration for iso and empty\n",
    "        df_sheets_level[j] = df_sheets_level[j][[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "        df_sheets_level[j].columns=[\"AVG_VEL_pixels/s\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "        df_sheets_level[j].reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #Removing the Nan row between the last reading a the 'sum'\n",
    "        df_sheets_level[j] = df_sheets_level[j].dropna(how='all')\n",
    "\n",
    "        # Creating time-column vector based on measurements' size\n",
    "        unit = 20/(len(df_sheets_level[j])-1)\n",
    "        TIME_minutes = np.arange(unit,21,unit)\n",
    "        TIME_minutes = np.append(TIME_minutes, \"SUM\")\n",
    "\n",
    "        # Adding time in minutes' column\n",
    "        df_sheets_level[j].insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "        \n",
    "        #Adding mouse information\n",
    "        df_sheets_level[j].insert(0,'SESSION_DRUG_GENDER', \n",
    "                                  [session + '_'drug + '_' + gender + '_' str(j+1)]*len(df_sheets_level[j]))\n",
    "\n",
    "        #Summations a diffrences of duration (empty vs iso)\n",
    "        summ = df_sheets_level[j][\"DURATION_EMPTY_s\"] + df_sheets_level[j][\"DURATION_ISO_s\"]\n",
    "        diff = df_sheets_level[j][\"DURATION_ISO_s\"] - df_sheets_level[j]['DURATION_EMPTY_s']\n",
    "        \n",
    "        # Changing any sum value from zero to 10^20\n",
    "        summ.loc[summ == 0] = pow(10,20)\n",
    "        \n",
    "        # Calculating relative and normalized socialindexes\n",
    "        df_sheets_level[j]['SOL_IDX_REL'] = 100 * diff/summ\n",
    "        df_sheets_level[j]['SOL_IDX_NORM'] = 100 * diff/(5*60)\n",
    "\n",
    "    ################################################################### # Finish of processing sheets\n",
    "    df_sheets_level = pd.concat(df_sheets_level)\n",
    "    df_files_level.append(df_sheets_level)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "################################################################################### # Finish of processing files\n",
    "appended_data = pd.concat(df_files_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22751a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going back to the main directory\n",
    "os.chdir(main_directory)\n",
    "\n",
    "# Exporting dt to csv\n",
    "appended_data.to_excel('3CT_data_vetical_format.xlsx',index=False)\n",
    "\n",
    "end = tm.time()\n",
    "\n",
    "# Priting running time and files processed\n",
    "print(i,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
