{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de3d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58709f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the current main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b0ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rreading the name of the subfoldeer\n",
    "subfolder_with_path = [f.path for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a1d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of files on subfolder\n",
    "list = os.listdir(subfolder_name[1]) \n",
    "number_files = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d707e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the folder\n",
    "os.chdir(subfolder_with_path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a loop to process all files and populate the main data-frame\n",
    "\n",
    "# Starting process timming\n",
    "start = tm.time()\n",
    "\n",
    "# Creating main data-frame\n",
    "df_files_level = [] #This array will contain data frames from each file as elements\n",
    "\n",
    "i = 0\n",
    "while i < number_files:\n",
    "    \n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    # Saving file's name\n",
    "    file = list[i]\n",
    "    \n",
    "    # Reading number and names of sheets\n",
    "    df_full = pd.read_excel(file, sheet_name = None)\n",
    "    sheets_names = df_full.keys()\n",
    "    numer_of_sheets = len(sheets_names)\n",
    "    \n",
    "    df_sheets_level = [\" \"]*number_of_sheets #This array will contain data frames from each sheets as elements\n",
    "    \n",
    "    # Reading files\n",
    "    ThreeCT_data = pd.ExcelFile(file)\n",
    "\n",
    "    # Saving group's name\n",
    "    group_name = file[0:8]\n",
    "\n",
    "    for j in range(0, numer_of_sheets):\n",
    "        \n",
    "        ##############################################\n",
    "        # Processing each sheet\n",
    "        ##############################################\n",
    "        \n",
    "        # Reading sheets within files\n",
    "        df_sheets_level[j] = ThreeCT_data.parse(j,header = None)\n",
    "\n",
    "        #Dropping the frist 13 rows and the row between the last reading and the \"sum\"\n",
    "        rows_to_drop = np.arange(13)\n",
    "        df_sheets_level[j] = df_sheets_level[j].drop(df_sheets_level[j].index[rows_to_drop])\n",
    "\n",
    "\n",
    "        #locating empty and iso columns\n",
    "        e = df_sheets_level[j].loc[13].where(df_sheets_level[j].loc[13].str.contains('empty')).dropna(how='all')\n",
    "        e.index #To getthe column value\n",
    "        empty = e.index[0]\n",
    "        s = df_sheets_level[j].loc[13].where(df_sheets_level[j].loc[13].str.contains('iso')).dropna(how='all')\n",
    "        s.index #To getthe column value\n",
    "        iso = s.index[0]\n",
    "\n",
    "        e2 = df2.loc[13].where(df2.loc[13].str.contains('empty')).dropna(how='all')\n",
    "        e2.index #To getthe column value\n",
    "        empty2 = e2.index[0]\n",
    "        s2 = df2.loc[13].where(df2.loc[13].str.contains('iso')).dropna(how='all')\n",
    "        s2.index #To getthe column value\n",
    "        iso2 = s2.index[0]\n",
    "\n",
    "        e3 = df3.loc[13].where(df3.loc[13].str.contains('empty')).dropna(how='all')\n",
    "        e3.index #To getthe column value\n",
    "        empty3 = e3.index[0]\n",
    "        s3 = df3.loc[13].where(df3.loc[13].str.contains('iso')).dropna(how='all')\n",
    "        s3.index #To getthe column value\n",
    "        iso3 = s3.index[0]\n",
    "\n",
    "        e4 = df4.loc[13].where(df4.loc[13].str.contains('empty')).dropna(how='all')\n",
    "        e4.index #To getthe column value\n",
    "        empty4 = e4.index[0]\n",
    "        s4 = df4.loc[13].where(df4.loc[13].str.contains('iso')).dropna(how='all')\n",
    "        s4.index #To getthe column value\n",
    "        iso4 = s4.index[0]\n",
    "\n",
    "        # Categorizing \"duration\" labels to iso or empty\n",
    "        df1.iloc[1:2, empty1:empty1+1] = 'Duration_empty_(s)'\n",
    "        df1.iloc[1:2, iso1:iso1+1] = 'Duration_iso_(s)'\n",
    "\n",
    "        df2.iloc[1:2, empty2:empty2+1] = 'Duration_empty_(s)'\n",
    "        df2.iloc[1:2, iso2:iso2+1] = 'Duration_iso_(s)'\n",
    "\n",
    "        df3.iloc[1:2, empty3:empty3+1] = 'Duration_empty_(s)'\n",
    "        df3.iloc[1:2, iso3:iso3+1] = 'Duration_iso_(s)'\n",
    "\n",
    "        df4.iloc[1:2, empty4:empty4+1] = 'Duration_empty_(s)'\n",
    "        df4.iloc[1:2, iso4:iso4+1] = 'Duration_iso_(s)'\n",
    "\n",
    "        #Dropping 13th row, now the 0th row\n",
    "        df1 = df1.drop(df1.index[0])\n",
    "        df2 = df2.drop(df2.index[0])\n",
    "        df3 = df3.drop(df3.index[0])\n",
    "        df4 = df4.drop(df4.index[0])\n",
    "\n",
    "        #Creating and assigning new header\n",
    "        new_header = df1.iloc[0] #grab the first row for the header\n",
    "        df1 = df1[1:] #take the data less the header row\n",
    "        df1.columns = new_header #set the header row as the df header\n",
    "        df2 = df2[1:] #take the data less the header row\n",
    "        df2.columns = new_header #set the header row as the df header\n",
    "        df3 = df3[1:] #take the data less the header row\n",
    "        df3.columns = new_header #set the header row as the df header\n",
    "        df4 = df4[1:] #take the data less the header row\n",
    "        df4.columns = new_header #set the header row as the df header\n",
    "\n",
    "        # Selecting columns of av verlocity and duration for iso and empty\n",
    "        df1 = df1[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "        df1.columns=[\"AVG_VEL_pixels/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "        df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df2 = df2[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "        df2.columns=[\"AVG_VEL_pixels/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "        df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df3 = df3[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "        df3.columns=[\"AVG_VEL_pixels/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "        df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df4 = df4[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "        df4.columns=[\"AVG_VEL_pixels/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "        df4.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #Removing the Nan row between the last reading a the 'sum'\n",
    "        df1 = df1.dropna(how='all')\n",
    "        df2 = df2.dropna(how='all')\n",
    "        df3 = df3.dropna(how='all')\n",
    "        df4 = df4.dropna(how='all')\n",
    "\n",
    "\n",
    "        # Creating time-column vector based on measurements' size\n",
    "        unit = 20/(len(df1)-1)\n",
    "        TIME_minutes = np.arange(unit,21,unit)\n",
    "        TIME_minutes = np.append(TIME_minutes, \"SUM\")\n",
    "\n",
    "          # Adding time in minutes' column\n",
    "        df1.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "        df2.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "        df3.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "        df4.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "\n",
    "        #Adding mouse name\n",
    "        df1.insert(0, 'MOUSE_NAME', [group_name + '_1']*len(df1))\n",
    "        df2.insert(0, 'MOUSE_NAME', [group_name + '_2']*len(df1))\n",
    "        df3.insert(0, 'MOUSE_NAME', [group_name + '_3']*len(df1))\n",
    "        df4.insert(0, 'MOUSE_NAME', [group_name + '_4']*len(df1))\n",
    "\n",
    "        #Summations a diffrences of duration (empty vs iso)\n",
    "        sum1 = df1[\"DURATION_EMPTY_s\"] + df1[\"DURATION_ISO_s\"]\n",
    "        sum2 = df2[\"DURATION_EMPTY_s\"] + df2[\"DURATION_ISO_s\"]\n",
    "        sum3 = df3[\"DURATION_EMPTY_s\"] + df3[\"DURATION_ISO_s\"]\n",
    "        sum4 = df4[\"DURATION_EMPTY_s\"] + df4[\"DURATION_ISO_s\"]\n",
    "\n",
    "        diff1 = df1[\"DURATION_ISO_s\"] - df1['DURATION_EMPTY_s']\n",
    "        diff2 = df2[\"DURATION_ISO_s\"] - df2['DURATION_EMPTY_s']\n",
    "        diff3 = df3[\"DURATION_ISO_s\"] - df3['DURATION_EMPTY_s']\n",
    "        diff4 = df4[\"DURATION_ISO_s\"] - df4['DURATION_EMPTY_s']\n",
    "\n",
    "        # Changin any sum value from zero to 10^20\n",
    "        sum1.loc[sum1 == 0] = pow(10,20)\n",
    "        sum2.loc[sum2 == 0] = pow(10,20)\n",
    "        sum3.loc[sum3 == 0] = pow(10,20)\n",
    "        sum4.loc[sum4 == 0] = pow(10,20)\n",
    "\n",
    "        # Calculating relative and normalized socialindexes\n",
    "        df1['SOL_IDX_REL'] = 100 * diff1/sum1\n",
    "        df2['SOL_IDX_REL'] = 100 * diff2/sum2\n",
    "        df3['SOL_IDX_REL'] = 100 * diff3/sum3\n",
    "        df4['SOL_IDX_REL'] = 100 * diff4/sum4\n",
    "\n",
    "        df1['SOL_IDX_NORM'] = 100 * diff1/(5*60)\n",
    "        df2['SOL_IDX_NORM'] = 100 * diff2/(5*60)\n",
    "        df3['SOL_IDX_NORM'] = 100 * diff3/(5*60)\n",
    "        df4['SOL_IDX_NORM'] = 100 * diff4/(5*60)\n",
    "\n",
    "        # Changin any sum value from zero to 10^20\n",
    "\n",
    "\n",
    "#         data_frames.append(df1)\n",
    "#         data_frames.append(df2)\n",
    "#         data_frames.append(df3)\n",
    "#         data_frames.append(df4)\n",
    "\n",
    "    ##########################################################################################################################\n",
    "    \n",
    "\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "appended_data = pd.concat(data_frames)\n",
    "end = tm.time()\n",
    "\n",
    "# Priting running time and files processed\n",
    "print(i,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') \n",
    "\n",
    "# Exporting dt to csv\n",
    "appended_data.to_excel('3CT_data.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22751a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going back to the main directory\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3eff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d22a303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving file's name\n",
    "file = list[0] #i = 0\n",
    "# Creating main data-frame\n",
    "df_files_level = [] #This array will contain data frames as elements\n",
    "\n",
    "\n",
    "# Reading number and names of sheets\n",
    "df_full = pd.read_excel(file, sheet_name = None)\n",
    "sheets_names = df_full.keys()\n",
    "numer_of_sheets = len(sheets_names)\n",
    "df_sheets_level = [\" \"] * numer_of_sheets\n",
    "\n",
    "# Reading files\n",
    "ThreeCT_data = pd.ExcelFile(file)\n",
    "\n",
    "# Saving group's name\n",
    "group_name = file[0:8]\n",
    "\n",
    "\n",
    "df_sheets_level[0] = ThreeCT_data.parse(0,header = None) # Reading sheets within files j = 0\n",
    "rows_to_drop = np.arange(13)\n",
    "df_sheets_level[0] = df_sheets_level[0].drop(df_sheets_level[0].index[rows_to_drop])\n",
    "\n",
    "#locating empty and iso columns\n",
    "e = df_sheets_level[0].loc[13].where(df_sheets_level[0].loc[13].str.contains('empty')).dropna(how='all')\n",
    "e.index #To getthe column value\n",
    "empty = e.index[0]\n",
    "s = df_sheets_level[0].loc[13].where(df_sheets_level[0].loc[13].str.contains('iso')).dropna(how='all')\n",
    "s.index #To getthe column value\n",
    "iso = s.index[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
