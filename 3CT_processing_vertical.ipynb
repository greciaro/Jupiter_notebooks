{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de3d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58709f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\greci\\\\Documents\\\\Jupiter_notebooks\\\\forJuliana'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the main directory\n",
    "main_directory = os.getcwd()\n",
    "main_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a1d0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting number of files on folder\n",
    "list = os.listdir('files') \n",
    "number_files = len(list)\n",
    "number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d707e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\greci\\\\Documents\\\\Jupiter_notebooks\\\\forJuliana\\\\files'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing directory to the folder\n",
    "os.chdir(r'C:\\\\Users\\\\greci\\\\Documents\\\\Jupiter_notebooks\\\\forJuliana\\\\files')\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a loop to process all files and populate the main data-frame\n",
    "\n",
    "# Starting process timming\n",
    "start = tm.time()\n",
    "\n",
    "# Creating main data-frame\n",
    "appended_data = [] #This array will contain df as elements\n",
    "\n",
    "i = 0\n",
    "while i < number_files:\n",
    "    \n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    # Saving file's name\n",
    "    file = list[i]\n",
    "    # Reading files\n",
    "    ThreeCT_data = pd.ExcelFile(file)\n",
    "\n",
    "    # Saving group's name\n",
    "    group_name = file[0:8]\n",
    "\n",
    "\n",
    "    # Reading sheets within files\n",
    "    df1 = pd.read_excel(ThreeCT_data, '1', header=None)\n",
    "    df2 = pd.read_excel(ThreeCT_data, '2', header=None)\n",
    "    df3 = pd.read_excel(ThreeCT_data, '3', header=None)\n",
    "    df4 = pd.read_excel(ThreeCT_data, '4', header=None)\n",
    "\n",
    "    #Dropping the frist 13 rows and the row between the last reading and the \"sum\"\n",
    "    rows_to_drop = np.arange(13)\n",
    "    df1 = df1.drop(df1.index[rows_to_drop])\n",
    "    df2 = df2.drop(df2.index[rows_to_drop])\n",
    "    df3 = df3.drop(df3.index[rows_to_drop])\n",
    "    df4 = df4.drop(df4.index[rows_to_drop])\n",
    "    \n",
    "    #locating empty and iso columns\n",
    "    e1 = df1.loc[13].where(df1.loc[13].str.contains('empty')).dropna(how='all')\n",
    "    e1.index #To getthe column value\n",
    "    empty1 = e1.index[0]\n",
    "    s1 = df1.loc[13].where(df1.loc[13].str.contains('iso')).dropna(how='all')\n",
    "    s1.index #To getthe column value\n",
    "    iso1 = s1.index[0]\n",
    "    \n",
    "    e2 = df2.loc[13].where(df2.loc[13].str.contains('empty')).dropna(how='all')\n",
    "    e2.index #To getthe column value\n",
    "    empty2 = e2.index[0]\n",
    "    s2 = df2.loc[13].where(df2.loc[13].str.contains('iso')).dropna(how='all')\n",
    "    s2.index #To getthe column value\n",
    "    iso2 = s2.index[0]\n",
    "    \n",
    "    e3 = df3.loc[13].where(df3.loc[13].str.contains('empty')).dropna(how='all')\n",
    "    e3.index #To getthe column value\n",
    "    empty3 = e3.index[0]\n",
    "    s3 = df3.loc[13].where(df3.loc[13].str.contains('iso')).dropna(how='all')\n",
    "    s3.index #To getthe column value\n",
    "    iso3 = s3.index[0]\n",
    "    \n",
    "    e4 = df4.loc[13].where(df4.loc[13].str.contains('empty')).dropna(how='all')\n",
    "    e4.index #To getthe column value\n",
    "    empty4 = e4.index[0]\n",
    "    s4 = df4.loc[13].where(df4.loc[13].str.contains('iso')).dropna(how='all')\n",
    "    s4.index #To getthe column value\n",
    "    iso4 = s4.index[0]\n",
    "    \n",
    "    # Categorizing \"duration\" labels to iso or empty\n",
    "    df1.iloc[1:2, empty1:empty1+1] = 'Duration_empty_(s)'\n",
    "    df1.iloc[1:2, iso1:iso1+1] = 'Duration_iso_(s)'\n",
    "    \n",
    "    df2.iloc[1:2, empty2:empty2+1] = 'Duration_empty_(s)'\n",
    "    df2.iloc[1:2, iso2:iso2+1] = 'Duration_iso_(s)'\n",
    "    \n",
    "    df3.iloc[1:2, empty3:empty3+1] = 'Duration_empty_(s)'\n",
    "    df3.iloc[1:2, iso3:iso3+1] = 'Duration_iso_(s)'\n",
    "    \n",
    "    df4.iloc[1:2, empty4:empty4+1] = 'Duration_empty_(s)'\n",
    "    df4.iloc[1:2, iso4:iso4+1] = 'Duration_iso_(s)'\n",
    "    \n",
    "    #Dropping 13th row, now the 0th row\n",
    "    df1 = df1.drop(df1.index[0])\n",
    "    df2 = df2.drop(df2.index[0])\n",
    "    df3 = df3.drop(df3.index[0])\n",
    "    df4 = df4.drop(df4.index[0])\n",
    "    \n",
    "    #Creating and assigning new header\n",
    "    new_header = df1.iloc[0] #grab the first row for the header\n",
    "    df1 = df1[1:] #take the data less the header row\n",
    "    df1.columns = new_header #set the header row as the df header\n",
    "    df2 = df2[1:] #take the data less the header row\n",
    "    df2.columns = new_header #set the header row as the df header\n",
    "    df3 = df3[1:] #take the data less the header row\n",
    "    df3.columns = new_header #set the header row as the df header\n",
    "    df4 = df4[1:] #take the data less the header row\n",
    "    df4.columns = new_header #set the header row as the df header\n",
    "\n",
    "    # Selecting columns of av verlocity and duration for iso and empty\n",
    "    df1 = df1[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "    df1.columns=[\"AVG_VEL_PIXELS/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df2 = df2[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "    df2.columns=[\"AVG_VEL_PIXELS/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df3 = df3[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "    df3.columns=[\"AVG_VEL_PIXELS/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "    df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df4 = df4[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "    df4.columns=[\"AVG_VEL_PIXELS/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "    df4.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #Removing the Nan row between the last reading a the 'sum'\n",
    "    df1 = df1.dropna(how='all')\n",
    "    df2 = df2.dropna(how='all')\n",
    "    df3 = df3.dropna(how='all')\n",
    "    df4 = df4.dropna(how='all')\n",
    "\n",
    "  \n",
    "    # Creating time-column vector based on measurements' size\n",
    "    unit = 20/(len(df1)-1)\n",
    "    TIME_minutes = np.arange(unit,21,unit)\n",
    "    TIME_minutes = np.append(TIME_minutes, \"SUM\")\n",
    "    \n",
    "      # Adding time in minutes' column\n",
    "    df1.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "    df2.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "    df3.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "    df4.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "\n",
    "    #Adding mouse name\n",
    "    df1.insert(0, 'MOUSE_NAME', [group_name + '_1']*5)\n",
    "    df2.insert(0, 'MOUSE_NAME', [group_name + '_2']*5)\n",
    "    df3.insert(0, 'MOUSE_NAME', [group_name + '_3']*5)\n",
    "    df4.insert(0, 'MOUSE_NAME', [group_name + '_4']*5)\n",
    "\n",
    "    #Summations a diffrences of duration (empty vs iso)\n",
    "    sum1 = df1[\"DURATION_EMPTY_s\"] + df1[\"DURATION_ISO_s\"]\n",
    "    sum2 = df2[\"DURATION_EMPTY_s\"] + df2[\"DURATION_ISO_s\"]\n",
    "    sum3 = df3[\"DURATION_EMPTY_s\"] + df3[\"DURATION_ISO_s\"]\n",
    "    sum4 = df4[\"DURATION_EMPTY_s\"] + df4[\"DURATION_ISO_s\"]\n",
    "    \n",
    "    diff1 = df1[\"DURATION_ISO_s\"] - df1['DURATION_EMPTY_s']\n",
    "    diff2 = df2[\"DURATION_ISO_s\"] - df2['DURATION_EMPTY_s']\n",
    "    diff3 = df3[\"DURATION_ISO_s\"] - df3['DURATION_EMPTY_s']\n",
    "    diff4 = df4[\"DURATION_ISO_s\"] - df4['DURATION_EMPTY_s']\n",
    "    \n",
    "    # Changin any sum value from zero to 10^20\n",
    "    sum1.loc[sum1 == 0] = pow(10,20)\n",
    "    sum2.loc[sum2 == 0] = pow(10,20)\n",
    "    sum3.loc[sum3 == 0] = pow(10,20)\n",
    "    sum4.loc[sum4 == 0] = pow(10,20)\n",
    "    \n",
    "    # Calculating relative a normalized socialindexes\n",
    "    df1['SOL_IDX_REL'] = 100 * diff1/sum1\n",
    "    df2['SOL_IDX_REL'] = 100 * diff2/sum2\n",
    "    df3['SOL_IDX_REL'] = 100 * diff3/sum3\n",
    "    df4['SOL_IDX_REL'] = 100 * diff4/sum4\n",
    "    \n",
    "    df1['SOL_IDX_NORM'] = 100 * diff1/(5*60)\n",
    "    df2['SOL_IDX_NORM'] = 100 * diff2/(5*60)\n",
    "    df3['SOL_IDX_NORM'] = 100 * diff3/(5*60)\n",
    "    df4['SOL_IDX_NORM'] = 100 * diff4/(5*60)\n",
    "    \n",
    "    # Changin any sum value from zero to 10^20\n",
    "    \n",
    "\n",
    "    appended_data.append(df1)\n",
    "    appended_data.append(df2)\n",
    "    appended_data.append(df3)\n",
    "    appended_data.append(df4)\n",
    "\n",
    "    ##########################################################################################################################\n",
    "    \n",
    "\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "appended_data = pd.concat(appended_data)\n",
    "end = tm.time()\n",
    "\n",
    "# Priting running time and files processed\n",
    "print(i,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') \n",
    "\n",
    "# Exporting dt to csv\n",
    "appended_data.to_excel('3CT_data.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4ea6ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_VEL_PIXELS/s)</th>\n",
       "      <th>DURATION_EMPTY_s</th>\n",
       "      <th>DURATION_ISO_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.2</td>\n",
       "      <td>82.3</td>\n",
       "      <td>209.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.2</td>\n",
       "      <td>99.5</td>\n",
       "      <td>185.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.7</td>\n",
       "      <td>119.8</td>\n",
       "      <td>163.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.4</td>\n",
       "      <td>91.6</td>\n",
       "      <td>183.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.4</td>\n",
       "      <td>393.2</td>\n",
       "      <td>742.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AVG_VEL_PIXELS/s) DURATION_EMPTY_s DURATION_ISO_s\n",
       "0              40.2             82.3          209.3\n",
       "1              27.2             99.5          185.8\n",
       "2              28.7            119.8          163.8\n",
       "3              25.4             91.6          183.3\n",
       "5              30.4            393.2          742.2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving file's name\n",
    "file = list[0]\n",
    "# Reading files\n",
    "ThreeCT_data = pd.ExcelFile(file)\n",
    "\n",
    "# Saving group's name\n",
    "group_name = file[0:8]\n",
    "\n",
    "\n",
    "# Reading sheets within files\n",
    "df1 = pd.read_excel(ThreeCT_data, '1', header=None)\n",
    "rows_to_drop = np.arange(13)\n",
    "#     rows_to_drop = np.append(rows_to_drop,[19])\n",
    "df1 = df1.drop(df1.index[rows_to_drop])\n",
    "\n",
    "#locating empty and iso columns\n",
    "e1 = df1.loc[13].where(df1.loc[13].str.contains('empty')).dropna(how='all')\n",
    "e1.index #To getthe column value\n",
    "empty1 = e1.index[0]\n",
    "s1 = df1.loc[13].where(df1.loc[13].str.contains('iso')).dropna(how='all')\n",
    "s1.index #To getthe column value\n",
    "iso1 = s1.index[0]\n",
    "\n",
    "# Categorizing \"duration\" labels to iso or empty\n",
    "df1.iloc[1:2, empty1:empty1+1] = 'Duration_empty_(s)'\n",
    "df1.iloc[1:2, iso1:iso1+1] = 'Duration_iso_(s)'\n",
    "\n",
    "    #Dropping 13th row, now the 0th row\n",
    "df1 = df1.drop(df1.index[0])\n",
    "\n",
    "    #Creating and assigning new header\n",
    "new_header = df1.iloc[0] #grab the first row for the header\n",
    "df1 = df1[1:] #take the data less the header row\n",
    "df1.columns = new_header #set the header row as the df header\n",
    "\n",
    "# Selecting columns of av verlocity and duration for iso and empty\n",
    "df1 = df1[[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "df1.columns=[\"AVG_VEL_PIXELS/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df1 = df1.dropna(how='all')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb7a8f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e22751a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5.0', '10.0', '15.0', '20.0', 'SUM'], dtype='<U32')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating time-column vector\n",
    "\n",
    "\n",
    "# a = numpy.append(a, a[0])\n",
    "\n",
    "# [5,10,15,20,\"SUM\"]\n",
    "#     df1.insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "TIME_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3180c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429941b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
