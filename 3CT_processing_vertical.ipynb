{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de3d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58709f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the current main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b0ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rreading the name of the subfoldeer\n",
    "subfolder_with_path = [f.path for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a1d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of files on subfolder\n",
    "list = os.listdir(subfolder_name[1]) \n",
    "number_files = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d707e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the folder\n",
    "os.chdir(subfolder_with_path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e662149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  Files processed \n",
      " \n",
      " Execution time: 0.28 seconds\n"
     ]
    }
   ],
   "source": [
    "#Using a loop to process all files and populate the main data-frame\n",
    "\n",
    "# Starting process timming\n",
    "start = tm.time()\n",
    "\n",
    "# Creating main data-frame\n",
    "df_files_level = [] #This array will contain data frames from each file as elements\n",
    "\n",
    "i = 0\n",
    "while i < number_files:\n",
    "    \n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    # Saving file's name\n",
    "    file = list[i]\n",
    "    \n",
    "    # Reading number and names of sheets\n",
    "    df_full = pd.read_excel(file, sheet_name = None)\n",
    "    sheets_names = df_full.keys()\n",
    "    number_of_sheets = len(sheets_names)\n",
    "    \n",
    "    df_sheets_level = [\" \"]*number_of_sheets #This array will contain data frames from each sheets as elements\n",
    "    \n",
    "    # Reading files\n",
    "    ThreeCT_data = pd.ExcelFile(file)\n",
    "\n",
    "    # Saving group's name\n",
    "    group_name = file[0:8]\n",
    "\n",
    "    for j in range(0, numer_of_sheets):\n",
    "        \n",
    "        ##############################################\n",
    "        # Processing each sheet\n",
    "        ##############################################\n",
    "        \n",
    "        # Reading sheets within files\n",
    "        df_sheets_level[j] = ThreeCT_data.parse(j,header = None)\n",
    "\n",
    "        #Dropping the frist 13 rows and the row between the last reading and the \"sum\"\n",
    "        rows_to_drop = np.arange(13)\n",
    "        df_sheets_level[j] = df_sheets_level[j].drop(df_sheets_level[j].index[rows_to_drop])\n",
    "\n",
    "\n",
    "        #locating empty and iso columns\n",
    "        e = df_sheets_level[j].loc[13].where(df_sheets_level[j].loc[13].str.contains('empty')).dropna(how='all')\n",
    "        e.index #To getthe column value\n",
    "        empty = e.index[0]\n",
    "        s = df_sheets_level[j].loc[13].where(df_sheets_level[j].loc[13].str.contains('iso')).dropna(how='all')\n",
    "        s.index #To getthe column value\n",
    "        iso = s.index[0]\n",
    "\n",
    "        # Categorizing \"duration\" labels wether iso or empty\n",
    "        df_sheets_level[j].iloc[1:2, empty:empty+1] = 'Duration_empty_(s)'\n",
    "        df_sheets_level[j].iloc[1:2, iso:iso+1] = 'Duration_iso_(s)'\n",
    "\n",
    "        #Dropping 13th row, now the 0th row\n",
    "        df_sheets_level[j] =  df_sheets_level[j].drop( df_sheets_level[j].index[0])\n",
    "\n",
    "        #Creating and assigning new header\n",
    "        new_header = df_sheets_level[j].iloc[0] #grab the first row for the header\n",
    "        df_sheets_level[j] = df_sheets_level[j][1:] #take the data less the header row\n",
    "        df_sheets_level[j].columns = new_header #set the header row as the df header\n",
    "        \n",
    "        # Selecting columns of av verlocity and duration for iso and empty\n",
    "        df_sheets_level[j] = df_sheets_level[j][[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "        df_sheets_level[j].columns=[\"AVG_VEL_pixels/s\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "        df_sheets_level[j].reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #Removing the Nan row between the last reading a the 'sum'\n",
    "        df_sheets_level[j] = df_sheets_level[j].dropna(how='all')\n",
    "\n",
    "        # Creating time-column vector based on measurements' size\n",
    "        unit = 20/(len(df_sheets_level[j])-1)\n",
    "        TIME_minutes = np.arange(unit,21,unit)\n",
    "        TIME_minutes = np.append(TIME_minutes, \"SUM\")\n",
    "\n",
    "        # Adding time in minutes' column\n",
    "        df_sheets_level[j].insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "        \n",
    "        #Adding mouse name\n",
    "        df_sheets_level[j].insert(0, 'MOUSE_NAME', [group_name + '_1']*len(df_sheets_level[j]))\n",
    "\n",
    "        #Summations a diffrences of duration (empty vs iso)\n",
    "        summ = df_sheets_level[j][\"DURATION_EMPTY_s\"] + df_sheets_level[j][\"DURATION_ISO_s\"]\n",
    "        diff = df_sheets_level[j][\"DURATION_ISO_s\"] - df_sheets_level[j]['DURATION_EMPTY_s']\n",
    "        \n",
    "        # Changing any sum value from zero to 10^20\n",
    "        summ.loc[summ == 0] = pow(10,20)\n",
    "        \n",
    "        # Calculating relative and normalized socialindexes\n",
    "        df_sheets_level[j]['SOL_IDX_REL'] = 100 * diff/summ\n",
    "        df_sheets_level[j]['SOL_IDX_NORM'] = 100 * diff/(5*60)\n",
    "\n",
    "    ################################################################### # Finish of processing sheets\n",
    "    df_sheets_level = pd.concat(df_sheets_level)\n",
    "    df_files_level.append(df_sheets_level)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "################################################################################### # Finish of processing files\n",
    "appended_data = pd.concat(df_files_level)\n",
    "end = tm.time()\n",
    "\n",
    "# Priting running time and files processed\n",
    "print(i,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') \n",
    "\n",
    "# Exporting dt to csv\n",
    "appended_data.to_excel('3CT_data_vetical_format.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e22751a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going back to the main directory\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3eff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d22a303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOUSE_NAME</th>\n",
       "      <th>TIME_STEP_minutes</th>\n",
       "      <th>AVG_VEL_pixels/s)</th>\n",
       "      <th>DURATION_EMPTY_s</th>\n",
       "      <th>DURATION_ISO_s</th>\n",
       "      <th>SOL_IDX_REL</th>\n",
       "      <th>SOL_IDX_NORM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Session1_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.2</td>\n",
       "      <td>82.3</td>\n",
       "      <td>209.3</td>\n",
       "      <td>43.552812</td>\n",
       "      <td>42.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Session1_1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>99.5</td>\n",
       "      <td>185.8</td>\n",
       "      <td>30.248861</td>\n",
       "      <td>28.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Session1_1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>119.8</td>\n",
       "      <td>163.8</td>\n",
       "      <td>15.51481</td>\n",
       "      <td>14.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Session1_1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>91.6</td>\n",
       "      <td>183.3</td>\n",
       "      <td>33.357585</td>\n",
       "      <td>30.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Session1_1</td>\n",
       "      <td>SUM</td>\n",
       "      <td>30.4</td>\n",
       "      <td>393.2</td>\n",
       "      <td>742.2</td>\n",
       "      <td>30.738066</td>\n",
       "      <td>116.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOUSE_NAME TIME_STEP_minutes AVG_VEL_pixels/s) DURATION_EMPTY_s  \\\n",
       "0  Session1_1               5.0              40.2             82.3   \n",
       "1  Session1_1              10.0              27.2             99.5   \n",
       "2  Session1_1              15.0              28.7            119.8   \n",
       "3  Session1_1              20.0              25.4             91.6   \n",
       "5  Session1_1               SUM              30.4            393.2   \n",
       "\n",
       "  DURATION_ISO_s SOL_IDX_REL SOL_IDX_NORM  \n",
       "0          209.3   43.552812    42.333333  \n",
       "1          185.8   30.248861    28.766667  \n",
       "2          163.8    15.51481    14.666667  \n",
       "3          183.3   33.357585    30.566667  \n",
       "5          742.2   30.738066   116.333333  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving file's name\n",
    "file = list[0] #i = 0\n",
    "# Creating main data-frame\n",
    "df_files_level = [] #This array will contain data frames as elements\n",
    "\n",
    "\n",
    "# Reading number and names of sheets\n",
    "df_full = pd.read_excel(file, sheet_name = None)\n",
    "sheets_names = df_full.keys()\n",
    "numer_of_sheets = len(sheets_names)\n",
    "df_sheets_level = [\" \"] * numer_of_sheets\n",
    "\n",
    "# Reading files\n",
    "ThreeCT_data = pd.ExcelFile(file)\n",
    "\n",
    "# Saving group's name\n",
    "group_name = file[0:8]\n",
    "\n",
    "\n",
    "df_sheets_level[0] = ThreeCT_data.parse(0,header = None) # Reading sheets within files j = 0\n",
    "rows_to_drop = np.arange(13)\n",
    "df_sheets_level[0] = df_sheets_level[0].drop(df_sheets_level[0].index[rows_to_drop])\n",
    "\n",
    "#locating empty and iso columns\n",
    "e = df_sheets_level[0].loc[13].where(df_sheets_level[0].loc[13].str.contains('empty')).dropna(how='all')\n",
    "e.index #To getthe column value\n",
    "empty = e.index[0]\n",
    "s = df_sheets_level[0].loc[13].where(df_sheets_level[0].loc[13].str.contains('iso')).dropna(how='all')\n",
    "s.index #To getthe column value\n",
    "iso = s.index[0]\n",
    "df_sheets_level[0].iloc[1:2, empty:empty+1] = 'Duration_empty_(s)'\n",
    "df_sheets_level[0].iloc[1:2, iso:iso+1] = 'Duration_iso_(s)'\n",
    "df_sheets_level[0] =  df_sheets_level[0].drop( df_sheets_level[0].index[0])\n",
    "\n",
    "#Creating and assigning new header\n",
    "new_header = df_sheets_level[0].iloc[0] #grab the first row for the header\n",
    "df_sheets_level[0] = df_sheets_level[0][1:] #take the data less the header row\n",
    "df_sheets_level[0].columns = new_header #set the header row as the df header\n",
    "\n",
    "# Selecting columns of av verlocity and duration for iso and empty\n",
    "df_sheets_level[0] = df_sheets_level[0][[\"Avg. velocity (pixels/s)\", \"Duration_empty_(s)\",\"Duration_iso_(s)\"]]\n",
    "df_sheets_level[0].columns=[\"AVG_VEL_pixels/s)\", \"DURATION_EMPTY_s\", \"DURATION_ISO_s\"]\n",
    "df_sheets_level[0].reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Removing the Nan row between the last reading a the 'sum'\n",
    "df_sheets_level[0] = df_sheets_level[0].dropna(how='all')\n",
    "\n",
    "# Creating time-column vector based on measurements' size\n",
    "unit = 20/(len(df_sheets_level[0])-1)\n",
    "TIME_minutes = np.arange(unit,21,unit)\n",
    "TIME_minutes = np.append(TIME_minutes, \"SUM\")\n",
    "\n",
    "# Adding time in minutes' column\n",
    "df_sheets_level[0].insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "\n",
    "#Adding mouse name\n",
    "df_sheets_level[0].insert(0, 'MOUSE_NAME', [group_name + '_1']*len(df_sheets_level[0]))\n",
    "\n",
    "#Summations a diffrences of duration (empty vs iso)\n",
    "summ = df_sheets_level[0][\"DURATION_EMPTY_s\"] + df_sheets_level[0][\"DURATION_ISO_s\"]\n",
    "diff = df_sheets_level[0][\"DURATION_ISO_s\"] - df_sheets_level[0]['DURATION_EMPTY_s']\n",
    "# Changing any sum value from zero to 10^20\n",
    "summ.loc[summ == 0] = pow(10,20)\n",
    "# Calculating relative and normalized socialindexes\n",
    "df_sheets_level[0]['SOL_IDX_REL'] = 100 * diff/summ\n",
    "df_sheets_level[0]['SOL_IDX_NORM'] = 100 * diff/(5*60)        \n",
    "#Summations a diffrences of duration (empty vs iso)\n",
    "summ = df_sheets_level[0][\"DURATION_EMPTY_s\"] + df_sheets_level[0][\"DURATION_ISO_s\"]\n",
    "diff = df_sheets_level[0][\"DURATION_ISO_s\"] - df_sheets_level[0]['DURATION_EMPTY_s']\n",
    "# Changing any sum value from zero to 10^20\n",
    "summ.loc[summ == 0] = pow(10,20)\n",
    "# Calculating relative and normalized socialindexes\n",
    "df_sheets_level[0]['SOL_IDX_REL'] = 100 * diff/summ\n",
    "df_sheets_level[0]['SOL_IDX_NORM'] = 100 * diff/(5*60)\n",
    "\n",
    "df_sheets_level[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
