{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de3d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58709f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the current main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b0ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rreading the name of the subfoldeer\n",
    "subfolder_with_path = [f.path for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a1d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of files on subfolder\n",
    "list = os.listdir(subfolder_name[1]) \n",
    "number_files = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d707e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the folder\n",
    "os.chdir(subfolder_with_path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e662149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  Files processed \n",
      " \n",
      " Execution time: 1.61 seconds\n"
     ]
    }
   ],
   "source": [
    "#Using a loop to process all files and populate the main data-frame\n",
    "\n",
    "# Starting process timming\n",
    "start = tm.time()\n",
    "\n",
    "# Creating main data-frame\n",
    "df_files_level = [] #This array will contain data frames from each file as elements\n",
    "\n",
    "i = 0\n",
    "while i < number_files:\n",
    "    \n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    # Saving file's name\n",
    "    file = list[i]\n",
    "    \n",
    "    # Reading number and names of sheets\n",
    "    df_full = pd.read_excel(file, sheet_name = None)\n",
    "    sheets_names = df_full.keys()\n",
    "    number_of_sheets = len(sheets_names)\n",
    "    \n",
    "    df_sheets_level = [\" \"]*number_of_sheets #This array will contain data frames from each sheets as elements\n",
    "    \n",
    "    # Reading files\n",
    "    ThreeCT_data = pd.ExcelFile(file)\n",
    "\n",
    "    # Saving group's name\n",
    "    group_name = file[0:2]\n",
    "\n",
    "    for j in range(0, number_of_sheets):\n",
    "        \n",
    "        ##############################################\n",
    "        # Processing each sheet\n",
    "        ##############################################\n",
    "        \n",
    "        # Reading sheets within files\n",
    "        df_sheets_level[j] = ThreeCT_data.parse(j,header = None)\n",
    "\n",
    "        #Dropping the frist 13 rows and the row between the last reading and the \"sum\"\n",
    "        rows_to_drop = np.arange(13)\n",
    "        df_sheets_level[j] = df_sheets_level[j].drop(df_sheets_level[j].index[rows_to_drop])\n",
    "\n",
    "\n",
    "        #locating empty and juv columns\n",
    "        e = df_sheets_level[j].loc[13].where(df_sheets_level[j].loc[13].str.contains('mpty')).dropna(how='all')\n",
    "        e.index #To ge tthe column value\n",
    "        empty = e.index[0]\n",
    "        s = df_sheets_level[j].loc[13].where(df_sheets_level[j].loc[13].str.contains('Juv')).dropna(how='all')\n",
    "        s.index #To getthe column value\n",
    "        iso = s.index[0]\n",
    "\n",
    "        # Categorizing \"duration\" labels wether iso or empty\n",
    "        df_sheets_level[j].iloc[1:2, empty:empty+1] = 'Duration_empty_(s)'\n",
    "        df_sheets_level[j].iloc[1:2, iso:iso+1] = 'Duration_juv_(s)'\n",
    "\n",
    "        #Dropping 13th row, now the 0th row\n",
    "        df_sheets_level[j] =  df_sheets_level[j].drop( df_sheets_level[j].index[0])\n",
    "\n",
    "        #Creating and assigning new header\n",
    "        new_header = df_sheets_level[j].iloc[0] #grab the first row for the header\n",
    "        df_sheets_level[j] = df_sheets_level[j][1:] #take the data less the header row\n",
    "        df_sheets_level[j].columns = new_header #set the header row as the df header\n",
    "        \n",
    "        # Selecting columns of av verlocity and duration for iso and empty\n",
    "        df_sheets_level[j] = df_sheets_level[j][[\"Avg. velocity (cm/s)\",\"Track length (cm)\", \"Duration_empty_(s)\",\"Duration_juv_(s)\"]]\n",
    "        df_sheets_level[j].columns=[\"AVG_VEL_cm/s\",\"LOCOMOTION_cm\", \"DURATION_EMPTY_s\", \"DURATION_JUV_s\"]\n",
    "        df_sheets_level[j].reset_index(drop=True, inplace=True)\n",
    "\n",
    "        #Removing the Nan row between the last reading a the 'sum'\n",
    "        df_sheets_level[j] = df_sheets_level[j].dropna(how='all')\n",
    "\n",
    "        # Creating time-column vector based on measurements' size\n",
    "        unit = 20/(len(df_sheets_level[j])-1)\n",
    "        TIME_minutes = np.arange(unit,21,unit)\n",
    "        TIME_minutes = np.append(TIME_minutes, \"SUM\")\n",
    "\n",
    "\n",
    "        # Adding time in minutes' column\n",
    "        df_sheets_level[j].insert(0, 'TIME_STEP_minutes', TIME_minutes)\n",
    "        \n",
    "        #Adding mouse name\n",
    "        df_sheets_level[j].insert(0, 'MOUSE_NAME', [group_name + '_' + str(j+1)]*len(df_sheets_level[j]))\n",
    "\n",
    "        #Summations a diffrences of duration (empty vs iso)\n",
    "        summ = df_sheets_level[j][\"DURATION_EMPTY_s\"] + df_sheets_level[j][\"DURATION_JUV_s\"]\n",
    "        diff = df_sheets_level[j][\"DURATION_JUV_s\"] - df_sheets_level[j]['DURATION_EMPTY_s']\n",
    "        \n",
    "        # Changing any sum value from zero to 10^20\n",
    "        summ.loc[summ == 0] = pow(10,20)\n",
    "        \n",
    "        # Calculating relative and normalized socialindexes\n",
    "        df_sheets_level[j]['SOCIAL_INTERACTION_RATIO'] = diff/summ\n",
    "        df_sheets_level[j]['NORMALIZED_SOCIAL_INTERACTION_RATIO'] = diff/(5*60)\n",
    "\n",
    "    ################################################################### # Finish of processing sheets\n",
    "    df_sheets_level = pd.concat(df_sheets_level)\n",
    "    df_files_level.append(df_sheets_level)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "################################################################################### # Finish of processing files\n",
    "appended_data = pd.concat(df_files_level)\n",
    "end = tm.time()\n",
    "\n",
    "# Priting running time and files processed\n",
    "print(i,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5da60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the column of \"SUM\" for locomotion\n",
    "sum_column_locomotion = pd.pivot_table(appended_data, values='LOCOMOTION_cm', index=['MOUSE_NAME'],\n",
    "                    columns=['TIME_STEP_minutes'], aggfunc=np.sum)\n",
    "sum_column_locomotion = sum_column_locomotion['SUM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e1bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the column of \"SUM\" for social interaction\n",
    "sum_column_social = pd.pivot_table(appended_data, values='SOCIAL_INTERACTION_RATIO', index=['MOUSE_NAME'],\n",
    "                    columns=['TIME_STEP_minutes'], aggfunc=np.sum)\n",
    "sum_column_social = sum_column_social['SUM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9513ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Changing the time step vector to numeric to obtain a properly sorted table\n",
    "appended_data['TIME_STEP_minutes']= pd.to_numeric(appended_data['TIME_STEP_minutes'], errors='coerce')\n",
    "\n",
    "#Creating the horizontal table pivoting from the vertical dataframe\n",
    "table = pd.pivot_table(appended_data, values='SOCIAL_INTERACTION_RATIO', index=['MOUSE_NAME'],\n",
    "                       columns=['TIME_STEP_minutes'], aggfunc=np.sum)\n",
    "#Adding the 'SUM' social column\n",
    "table['SUM'] = sum_column_social\n",
    "\n",
    "#Adding the 'SUM' locomotion column\n",
    "table['LOCOMOTION_cm'] = sum_column_locomotion\n",
    "\n",
    "# exporting table to Excel\n",
    "table.to_excel('3CT_data_horizontal_format.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22751a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going back to the main directory\n",
    "os.chdir(main_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
