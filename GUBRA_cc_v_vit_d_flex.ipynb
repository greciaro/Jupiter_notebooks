{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stanting timming process\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_with_path = [\"\" for i in range(4)]\n",
    "subfolder_with_path[0] = main_directory + '/'+'01Activity_files'\n",
    "subfolder_with_path[1] = main_directory + '/'+'02Volume_files'\n",
    "subfolder_with_path[2] = main_directory + '/'+'03Volume_in_tissue_files'\n",
    "subfolder_with_path[3] = main_directory + '/'+'zzz_input_and_reference_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Importing information from \"samples overview\", \"intensisties template\" and \"brain allen map\"\n",
    "###############################################################################################\n",
    "\n",
    "# Changing directory to the \"zzz_input_and_reference_files\" folder\n",
    "os.chdir(subfolder_with_path[-1])\n",
    "\n",
    "\n",
    "# Reading \"sample_overview.csv\" file\n",
    "samples_overview = pd.read_csv(\"sample_overview.csv\", \n",
    "                               dtype={\"SAMPLE\": int,\n",
    "                                      \"hemisphere\": \"string\",\"marker\": \"string\",\n",
    "                                      \"TX_GROUP\": \"string\"})\n",
    "\n",
    "# Reading \"gubra_intensities_template.csv\" file\n",
    "gubra_intensities_template = pd.read_csv(\"gubra_intensities_template.csv\",\n",
    "                                   dtype={\"IDPath\": \"string\", \n",
    "                                          \"LabelID\": int, \n",
    "                                          \"raw\": \"string\", \n",
    "                                          \"LabelAbrv\": \"string\"})\n",
    "# Reading \"brain_allen_map.csv\" file\n",
    "brain_gubra_map = pd.read_csv(\"brain_gubra_map_fixed.csv\", \n",
    "                               dtype={\"IDPath\": \"string\", \"LabelAbrv\": \"string\",\n",
    "                                      \"raw\": \"string\",\"allen_1\": \"string\",\n",
    "                                      \"allen_2\": \"string\",\"allen_3\": \"string\",\n",
    "                                      \"allen_4\": \"string\",\"allen_5\": \"string\",\n",
    "                                      \"allen_6\": \"string\",\"allen_7\": \"string\",\n",
    "                                      \"fine\": \"string\",\"medium\": \"string\",\n",
    "                                      \"coarse\": \"string\", \"all\":\"string\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving drugs and markers' names from the \"sample_overview\" file\n",
    "\n",
    "drugs = samples_overview['TX_GROUP'].unique()\n",
    "markers = samples_overview['marker'].unique()\n",
    "\n",
    "d = 0\n",
    "m = 0\n",
    "counters_names = []\n",
    "while (m < len(markers)):\n",
    "    while (d < len(drugs)):\n",
    "        counters_names.append(drugs[d] + '_' + markers[m])\n",
    "        d += 1\n",
    "    m += 1\n",
    "    d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"02Volume_files\" folder\n",
    "os.chdir(subfolder_with_path[1])\n",
    "\n",
    "#Counting number of files on \"02Volume_files\" folder\n",
    "list = os.listdir(subfolder_with_path[1]) \n",
    "number_files = len(list)\n",
    "number_volume_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_data = [] #This array will contain df as elements\n",
    "\n",
    "#Staring counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    \n",
    "    file = list[i]\n",
    "    # Saving sample's number\n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "\n",
    "    # Reading file's data\n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME'] = output['VOLUME'].div(1000000).round(7)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = 'v_' + output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))    \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "volume_data = pd.concat(volume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"03Volume_in_tissue_files\" folder\n",
    "os.chdir(subfolder_with_path[2])\n",
    "\n",
    "#Counting number of files on \"03Volume_in_tissue_files\" folder\n",
    "list = os.listdir(subfolder_with_path[2]) \n",
    "number_files = len(list)\n",
    "number_volintissue_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_intissue_data = [] #This array will contain df as elements\n",
    "\n",
    "#Staring counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "\n",
    "    file = list[i]\n",
    "    # Saving sample's number \n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME_IN_TISSUE'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME_IN_TISSUE'] = output['VOLUME_IN_TISSUE'].div(1000000).round(6)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = 'vit_' + output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))    \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_intissue_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframeo\n",
    "volume_intissue_data = pd.concat(volume_intissue_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating volume ratio\n",
    "volumes_data = pd.merge(volume_intissue_data,volume_data[['raw','VOLUME','SAMPLE']],on=('raw','SAMPLE'),how='left')\n",
    "volumes_data['volumes_ratio'] = volumes_data['VOLUME_IN_TISSUE'] / volumes_data['VOLUME'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have nicknames as columns\n",
    "pivoted_volumesintissue_data = pd.pivot_table(volume_intissue_data, values='VOLUME_IN_TISSUE', \n",
    "                                       index=['raw','SAMPLE'],columns=['nickname'], aggfunc=np.sum)\n",
    "#Restarting index to activate'raw' and 'marker' as columns\n",
    "pivoted_volumesintissue_data = pivoted_volumesintissue_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have nicknames as columns\n",
    "pivoted_volumes_data = pd.pivot_table(volume_data, values='VOLUME', \n",
    "                                       index=['raw', 'SAMPLE'],columns=['nickname'], aggfunc=np.sum)\n",
    "#Restarting index to activate'raw' and 'marker' as columns\n",
    "pivoted_volumes_data = pivoted_volumes_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"01Activity_files\" folder\n",
    "os.chdir(subfolder_with_path[0])\n",
    "\n",
    "#Counting number of files on \"01Activity_files\" folder\n",
    "list = os.listdir(subfolder_with_path[0]) \n",
    "number_files = len(list)\n",
    "number_activity_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "activity_data = [] #This array will contain df as elements\n",
    "\n",
    "#Staring counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "\n",
    "    ##############################################\n",
    "    # Innitiates loop to process each file\n",
    "    ##############################################\n",
    "\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "    # Working with each file at a time\n",
    "    file = list[i]\n",
    "    \n",
    "    # Saving sample's number\n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    regions_count_activity_fracc = pd.read_csv(file,low_memory=False)\n",
    "    regions_count_activity_fracc = regions_count_activity_fracc[regions_count_activity_fracc.PIXEL_COUNT != \"PIXEL_COUNT\"]        \n",
    "\n",
    "    # Adding-up regions' fracctions\n",
    "    regions_fracc_1 = regions_count_activity_fracc[[\"INTENSITY_1\", \"INTENSITY_1_PERC\"]]\n",
    "    regions_fracc_2 = regions_count_activity_fracc[[\"INTENSITY_2\", \"INTENSITY_2_PERC\"]]\n",
    "    regions_fracc_3 = regions_count_activity_fracc[[\"INTENSITY_3\", \"INTENSITY_3_PERC\"]]\n",
    "    regions_fracc_1 = regions_fracc_1.rename(columns={\"INTENSITY_1\": \"INTENSITY\",\"INTENSITY_1_PERC\" : \"COUNTS\"})\n",
    "    regions_fracc_2 = regions_fracc_2.rename(columns={\"INTENSITY_2\": \"INTENSITY\",\"INTENSITY_2_PERC\" : \"COUNTS\"})\n",
    "    regions_fracc_3 = regions_fracc_3.rename(columns={\"INTENSITY_3\": \"INTENSITY\",\"INTENSITY_3_PERC\" : \"COUNTS\"})\n",
    "    total_region_activity = regions_fracc_1.append(regions_fracc_2, \n",
    "                                                   ignore_index=True).append(regions_fracc_3, ignore_index=True)\n",
    "    total_region_activity[\"COUNTS\"] = total_region_activity[\"COUNTS\"].astype(float)\n",
    "    total_region_activity = total_region_activity.groupby(['INTENSITY']).agg('sum').reset_index()\n",
    "#     total_region_activity[\"COUNTS\"] = total_region_activity[\"COUNTS\"].round(0)\n",
    "    total_region_activity[\"INTENSITY\"] = total_region_activity[\"INTENSITY\"].astype(int)\n",
    "        \n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(total_region_activity, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    activity_label_name = 'ACTIVITY'\n",
    "    output = output.rename(columns = {'COUNTS':activity_label_name})\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))    \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "\n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    activity_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "activity_data = pd.concat(activity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing empty cells with zeros\n",
    "activity_data['ACTIVITY'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating density dataframe\n",
    "##Merging activity, volume and volume in tissue dataframes\n",
    "density = pd.merge(activity_data,\n",
    "                                  volumes_data[['raw','SAMPLE','VOLUME']],\n",
    "                                  on=['raw','SAMPLE'],\n",
    "                                  how='left')\n",
    "density = pd.merge(density,\n",
    "                           volume_intissue_data[['raw','SAMPLE','VOLUME_IN_TISSUE']],\n",
    "                           on=['raw','SAMPLE'],\n",
    "                           how='left')\n",
    "#Creating the density nickname (d_nickname)\n",
    "density['DENSITY'] = density['ACTIVITY'] / density['VOLUME_IN_TISSUE']\n",
    "\n",
    "# Changing directory to the main path\n",
    "os.chdir(main_directory)\n",
    "#Printing all columns\n",
    "density.to_csv('GUBRA_output_all_columns.csv', index=False)\n",
    "\n",
    "density['d_nickname'] = 'd_' + density['nickname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have d_nicknames as columns\n",
    "pivoted_density = pd.pivot_table(density, values='DENSITY', \n",
    "                                       index=['raw', 'SAMPLE'],columns=['d_nickname'], aggfunc=np.sum)\n",
    "#Restarting index to activate'raw' and 'marker' as columns\n",
    "pivoted_density = pivoted_density.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging activity and volume ratio to filter activity where the volume ratio is below 50%\n",
    "filtered_activity_data = pd.merge(activity_data,\n",
    "                                  volumes_data[['raw','SAMPLE','volumes_ratio']],\n",
    "                                  on=['raw','SAMPLE'],\n",
    "                                  how='left')\n",
    "filtered_activity_data.loc[(filtered_activity_data['volumes_ratio'] < 0.5),'ACTIVITY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have nicknames as columns\n",
    "pivoted_activity_data = pd.pivot_table(filtered_activity_data, values='ACTIVITY', \n",
    "                               index=['raw','hemisphere','marker','SAMPLE'],columns=['nickname'], aggfunc=np.sum)\n",
    "\n",
    "#Restarting index to activate'hemisphere','marker'and 'rater' as columns\n",
    "pivoted_activity_data = pivoted_activity_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all dataframes\n",
    "gubra_and_activity = pd.merge(brain_gubra_map,pivoted_activity_data,on='raw',how='right')\n",
    "cell_count_output = pd.merge(gubra_and_activity,pivoted_volumesintissue_data,on=['raw','SAMPLE'],how='left')\n",
    "cell_count_output = pd.merge(cell_count_output,pivoted_volumes_data,on=['raw','SAMPLE'],how='left')\n",
    "cell_count_output = pd.merge(cell_count_output,pivoted_density,on=['raw','SAMPLE'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the main path\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the \"cell_count_output.csv\" file\n",
    "cell_count_output.to_csv('GUBRA_output_for_ADX.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Creating output for Dan's Excel analysis\n",
    "\n",
    "\n",
    "#Chaging SAMPLE elements to integer and then to string when adding the letter \"S\"\n",
    "filtered_activity_data['SAMPLE_STR'] = filtered_activity_data['SAMPLE'].astype(int)\n",
    "filtered_activity_data['SAMPLE_STR'] = filtered_activity_data['SAMPLE_STR'].astype(str)\n",
    "filtered_activity_data['SAMPLE_STR'] = 'S' + filtered_activity_data['SAMPLE_STR']\n",
    "\n",
    "#Pivoting dataframe to have sample as columns\n",
    "pivoted_activity_Dan = pd.pivot_table(filtered_activity_data, values='ACTIVITY', \n",
    "                               index=['raw','hemisphere',\n",
    "                                      'marker','SAMPLE'],\n",
    "                                      columns=['SAMPLE_STR','TX_GROUP'], aggfunc=np.sum)\n",
    "\n",
    "#Restarting index to activate'hemisphere','marker' as columns\n",
    "pivoted_activity_Dan = pivoted_activity_Dan.reset_index()\n",
    "\n",
    "#Adding GUBRA map columns\n",
    "gubra_and_activity_Dan = pd.merge(brain_gubra_map,pivoted_activity_Dan,on='raw',how='right')\n",
    "\n",
    "#Editing output\n",
    "gubra_and_activity_Dan.rename(columns={('SAMPLE', ''): 'SAMPLE',\n",
    "                                       ('hemisphere', ''): 'hemisphere',\n",
    "                                       ('marker', ''): 'marker',\n",
    "                                       'raw': 'LabelName'}, inplace=True)\n",
    "gubra_and_activity_Dan = gubra_and_activity_Dan.drop(columns=['allen_1', 'allen_2',\n",
    "                                     'allen_3', 'allen_4',\n",
    "                                     'allen_5', 'allen_6',\n",
    "                                     'allen_7', 'fine',\n",
    "                                     'medium', 'coarse','all',\n",
    "                                    'SAMPLE', 'hemisphere','marker'])\n",
    "gubra_and_activity_Dan = gubra_and_activity_Dan.groupby('IDPath').apply(lambda x: x\\\n",
    "                                                                        .fillna(method='ffill')\\\n",
    "                                                                        .fillna(method='bfill')\\\n",
    "                                                                        .drop_duplicates()\\\n",
    "                                                                        .reset_index(drop=True))\n",
    "\n",
    "# gubra_and_activity_Dan.columns = gubra_and_activity_Dan.columns.values.str.replace('[),(]', '')\n",
    "# gubra_and_activity_Dan.columns = gubra_and_activity_Dan.columns.values.str.replace('[,]', '_')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#editing columns names from ('sample43', 'psilocybin') to S43_psilocybin\n",
    "columns_name_array = gubra_and_activity_Dan.columns.values\n",
    "#dividing into two arrays, one with str and one with tuple\n",
    "#\"cna\" = column_name+array\n",
    "number_of_cols = columns_name_array.size\n",
    "cna_1 = columns_name_array[0:3]\n",
    "cna_2 = columns_name_array[-(number_of_cols - 3):]\n",
    "str = ''\n",
    "for item in cna_2:\n",
    "    str = str +'_'.join(item) + ' ' \n",
    "str = str.split(' ')[:-1]\n",
    "new_columns_name = np.concatenate([cna_1, str]) \n",
    "new_columns_name\n",
    "#Asingning new column names to the dataframe\n",
    "gubra_and_activity_Dan = gubra_and_activity_Dan.set_axis(new_columns_name, axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>IDPath</th>\n",
       "      <th>LabelAbrv</th>\n",
       "      <th>LabelName</th>\n",
       "      <th>S51_saline</th>\n",
       "      <th>S53_saline</th>\n",
       "      <th>S43_psilocybin</th>\n",
       "      <th>S44_psilocybin</th>\n",
       "      <th>S46_psilocybin</th>\n",
       "      <th>S47_psilocybin</th>\n",
       "      <th>S48_psilocybin</th>\n",
       "      <th>S50_psilocybin</th>\n",
       "      <th>S52_psilocybin</th>\n",
       "      <th>S54_psilocybin</th>\n",
       "      <th>S56_psilocybin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDPath</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/997/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/</td>\n",
       "      <td>root</td>\n",
       "      <td>root</td>\n",
       "      <td>12184.8</td>\n",
       "      <td>11185.1</td>\n",
       "      <td>6817.086</td>\n",
       "      <td>3654.76</td>\n",
       "      <td>3477.64</td>\n",
       "      <td>11518.2</td>\n",
       "      <td>4812.09</td>\n",
       "      <td>3892.38</td>\n",
       "      <td>7887.16</td>\n",
       "      <td>10952.2</td>\n",
       "      <td>5444.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/1009/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/1009/</td>\n",
       "      <td>fiber tracts</td>\n",
       "      <td>fiber_tracts</td>\n",
       "      <td>1648.01</td>\n",
       "      <td>1803.22</td>\n",
       "      <td>1362.769</td>\n",
       "      <td>1751.84</td>\n",
       "      <td>1856.2</td>\n",
       "      <td>1532.07</td>\n",
       "      <td>1582.3</td>\n",
       "      <td>1531.87</td>\n",
       "      <td>1670.74</td>\n",
       "      <td>2646.26</td>\n",
       "      <td>1678.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/1009/1000/760/102/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/1009/1000/760/102/</td>\n",
       "      <td>nst</td>\n",
       "      <td>nigrostriatal_tract</td>\n",
       "      <td>100.341</td>\n",
       "      <td>154.205</td>\n",
       "      <td>43.200</td>\n",
       "      <td>109.315</td>\n",
       "      <td>91.148</td>\n",
       "      <td>78.148</td>\n",
       "      <td>74.145</td>\n",
       "      <td>43.502</td>\n",
       "      <td>166.327</td>\n",
       "      <td>131.205</td>\n",
       "      <td>41.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/1009/1000/863/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/1009/1000/863/</td>\n",
       "      <td>rust</td>\n",
       "      <td>rubrospinal_tract</td>\n",
       "      <td>810.646</td>\n",
       "      <td>791.676</td>\n",
       "      <td>374.805</td>\n",
       "      <td>344.827</td>\n",
       "      <td>437.666</td>\n",
       "      <td>393.167</td>\n",
       "      <td>346.535</td>\n",
       "      <td>240.884</td>\n",
       "      <td>486.192</td>\n",
       "      <td>693.927</td>\n",
       "      <td>360.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/1009/1000/863/397/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/1009/1000/863/397/</td>\n",
       "      <td>vtd</td>\n",
       "      <td>ventral_tegmental_decussation</td>\n",
       "      <td>44.677</td>\n",
       "      <td>19.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.333</td>\n",
       "      <td>16.615</td>\n",
       "      <td>59.729</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>21.274</td>\n",
       "      <td>53.814</td>\n",
       "      <td>20.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/8/567/688/703/319/334/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/8/567/688/703/319/334/</td>\n",
       "      <td>BMAp</td>\n",
       "      <td>Basomedial_amygdalar_nucleus_posterior_part</td>\n",
       "      <td>979.259</td>\n",
       "      <td>1350.21</td>\n",
       "      <td>813.844</td>\n",
       "      <td>1094.75</td>\n",
       "      <td>1845.12</td>\n",
       "      <td>686.723</td>\n",
       "      <td>1148.86</td>\n",
       "      <td>1426.21</td>\n",
       "      <td>1819.3</td>\n",
       "      <td>1833.87</td>\n",
       "      <td>1630.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/8/567/688/703/583/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/8/567/688/703/583/</td>\n",
       "      <td>CLA</td>\n",
       "      <td>Claustrum</td>\n",
       "      <td>625.643</td>\n",
       "      <td>1005.87</td>\n",
       "      <td>774.092</td>\n",
       "      <td>1201.64</td>\n",
       "      <td>1773.95</td>\n",
       "      <td>739.655</td>\n",
       "      <td>1627.73</td>\n",
       "      <td>1610.8</td>\n",
       "      <td>1623.16</td>\n",
       "      <td>1542.62</td>\n",
       "      <td>1626.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/8/567/688/703/780/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/8/567/688/703/780/</td>\n",
       "      <td>PA</td>\n",
       "      <td>Posterior_amygdalar_nucleus</td>\n",
       "      <td>1621.59</td>\n",
       "      <td>2133.12</td>\n",
       "      <td>945.919</td>\n",
       "      <td>889.157</td>\n",
       "      <td>1453.95</td>\n",
       "      <td>630.717</td>\n",
       "      <td>851.603</td>\n",
       "      <td>1106.03</td>\n",
       "      <td>2245.92</td>\n",
       "      <td>2503.68</td>\n",
       "      <td>2029.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/8/567/688/703/942/952/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/8/567/688/703/942/952/</td>\n",
       "      <td>EPd</td>\n",
       "      <td>Endopiriform_nucleus_dorsal_part</td>\n",
       "      <td>1649.59</td>\n",
       "      <td>2975.35</td>\n",
       "      <td>2330.138</td>\n",
       "      <td>4516.03</td>\n",
       "      <td>5332.34</td>\n",
       "      <td>1791.88</td>\n",
       "      <td>4744.21</td>\n",
       "      <td>4552.45</td>\n",
       "      <td>5874.32</td>\n",
       "      <td>5246.14</td>\n",
       "      <td>4942.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/997/8/567/688/703/942/966/</th>\n",
       "      <th>0</th>\n",
       "      <td>/997/8/567/688/703/942/966/</td>\n",
       "      <td>EPv</td>\n",
       "      <td>Endopiriform_nucleus_ventral_part</td>\n",
       "      <td>777.59</td>\n",
       "      <td>1414.91</td>\n",
       "      <td>747.274</td>\n",
       "      <td>1504.19</td>\n",
       "      <td>1737.93</td>\n",
       "      <td>318.776</td>\n",
       "      <td>1524.95</td>\n",
       "      <td>1299.43</td>\n",
       "      <td>1959.37</td>\n",
       "      <td>1772.4</td>\n",
       "      <td>1860.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    IDPath     LabelAbrv  \\\n",
       "IDPath                                                                     \n",
       "/997/                       0                        /997/          root   \n",
       "/997/1009/                  0                   /997/1009/  fiber tracts   \n",
       "/997/1009/1000/760/102/     0      /997/1009/1000/760/102/           nst   \n",
       "/997/1009/1000/863/         0          /997/1009/1000/863/          rust   \n",
       "/997/1009/1000/863/397/     0      /997/1009/1000/863/397/           vtd   \n",
       "...                                                    ...           ...   \n",
       "/997/8/567/688/703/319/334/ 0  /997/8/567/688/703/319/334/          BMAp   \n",
       "/997/8/567/688/703/583/     0      /997/8/567/688/703/583/           CLA   \n",
       "/997/8/567/688/703/780/     0      /997/8/567/688/703/780/            PA   \n",
       "/997/8/567/688/703/942/952/ 0  /997/8/567/688/703/942/952/           EPd   \n",
       "/997/8/567/688/703/942/966/ 0  /997/8/567/688/703/942/966/           EPv   \n",
       "\n",
       "                                                                 LabelName  \\\n",
       "IDPath                                                                       \n",
       "/997/                       0                                         root   \n",
       "/997/1009/                  0                                 fiber_tracts   \n",
       "/997/1009/1000/760/102/     0                          nigrostriatal_tract   \n",
       "/997/1009/1000/863/         0                            rubrospinal_tract   \n",
       "/997/1009/1000/863/397/     0                ventral_tegmental_decussation   \n",
       "...                                                                    ...   \n",
       "/997/8/567/688/703/319/334/ 0  Basomedial_amygdalar_nucleus_posterior_part   \n",
       "/997/8/567/688/703/583/     0                                    Claustrum   \n",
       "/997/8/567/688/703/780/     0                  Posterior_amygdalar_nucleus   \n",
       "/997/8/567/688/703/942/952/ 0             Endopiriform_nucleus_dorsal_part   \n",
       "/997/8/567/688/703/942/966/ 0            Endopiriform_nucleus_ventral_part   \n",
       "\n",
       "                              S51_saline S53_saline  S43_psilocybin  \\\n",
       "IDPath                                                                \n",
       "/997/                       0    12184.8    11185.1        6817.086   \n",
       "/997/1009/                  0    1648.01    1803.22        1362.769   \n",
       "/997/1009/1000/760/102/     0    100.341    154.205          43.200   \n",
       "/997/1009/1000/863/         0    810.646    791.676         374.805   \n",
       "/997/1009/1000/863/397/     0     44.677     19.064           0.000   \n",
       "...                                  ...        ...             ...   \n",
       "/997/8/567/688/703/319/334/ 0    979.259    1350.21         813.844   \n",
       "/997/8/567/688/703/583/     0    625.643    1005.87         774.092   \n",
       "/997/8/567/688/703/780/     0    1621.59    2133.12         945.919   \n",
       "/997/8/567/688/703/942/952/ 0    1649.59    2975.35        2330.138   \n",
       "/997/8/567/688/703/942/966/ 0     777.59    1414.91         747.274   \n",
       "\n",
       "                              S44_psilocybin S46_psilocybin S47_psilocybin  \\\n",
       "IDPath                                                                       \n",
       "/997/                       0        3654.76        3477.64        11518.2   \n",
       "/997/1009/                  0        1751.84         1856.2        1532.07   \n",
       "/997/1009/1000/760/102/     0        109.315         91.148         78.148   \n",
       "/997/1009/1000/863/         0        344.827        437.666        393.167   \n",
       "/997/1009/1000/863/397/     0          5.333         16.615         59.729   \n",
       "...                                      ...            ...            ...   \n",
       "/997/8/567/688/703/319/334/ 0        1094.75        1845.12        686.723   \n",
       "/997/8/567/688/703/583/     0        1201.64        1773.95        739.655   \n",
       "/997/8/567/688/703/780/     0        889.157        1453.95        630.717   \n",
       "/997/8/567/688/703/942/952/ 0        4516.03        5332.34        1791.88   \n",
       "/997/8/567/688/703/942/966/ 0        1504.19        1737.93        318.776   \n",
       "\n",
       "                              S48_psilocybin S50_psilocybin S52_psilocybin  \\\n",
       "IDPath                                                                       \n",
       "/997/                       0        4812.09        3892.38        7887.16   \n",
       "/997/1009/                  0         1582.3        1531.87        1670.74   \n",
       "/997/1009/1000/760/102/     0         74.145         43.502        166.327   \n",
       "/997/1009/1000/863/         0        346.535        240.884        486.192   \n",
       "/997/1009/1000/863/397/     0            9.5              5         21.274   \n",
       "...                                      ...            ...            ...   \n",
       "/997/8/567/688/703/319/334/ 0        1148.86        1426.21         1819.3   \n",
       "/997/8/567/688/703/583/     0        1627.73         1610.8        1623.16   \n",
       "/997/8/567/688/703/780/     0        851.603        1106.03        2245.92   \n",
       "/997/8/567/688/703/942/952/ 0        4744.21        4552.45        5874.32   \n",
       "/997/8/567/688/703/942/966/ 0        1524.95        1299.43        1959.37   \n",
       "\n",
       "                              S54_psilocybin S56_psilocybin  \n",
       "IDPath                                                       \n",
       "/997/                       0        10952.2        5444.07  \n",
       "/997/1009/                  0        2646.26        1678.86  \n",
       "/997/1009/1000/760/102/     0        131.205         41.576  \n",
       "/997/1009/1000/863/         0        693.927        360.589  \n",
       "/997/1009/1000/863/397/     0         53.814         20.972  \n",
       "...                                      ...            ...  \n",
       "/997/8/567/688/703/319/334/ 0        1833.87        1630.54  \n",
       "/997/8/567/688/703/583/     0        1542.62        1626.75  \n",
       "/997/8/567/688/703/780/     0        2503.68        2029.25  \n",
       "/997/8/567/688/703/942/952/ 0        5246.14        4942.73  \n",
       "/997/8/567/688/703/942/966/ 0         1772.4        1860.36  \n",
       "\n",
       "[593 rows x 14 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ordering columns so all saline samples are fisrt\n",
    "cols = gubra_and_activity_Dan.columns.tolist()\n",
    "cols_first_3 = cna_1\n",
    "cols_samples = cols[-(number_of_cols - 3):]\n",
    "\n",
    "def w_len(e):\n",
    "    len_e = len(e)\n",
    "    if e.endswith(\"saline\"):\n",
    "        len_e = 1\n",
    "    return len_e\n",
    "\n",
    "cols_samples.sort(key=w_len)\n",
    "new_cols = np.concatenate((cols_first_3, cols_samples), axis=None)\n",
    "\n",
    "gubra_and_activity_Dan = gubra_and_activity_Dan[new_cols]\n",
    "\n",
    "gubra_and_activity_Dan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gubra_and_activity_Dan.to_csv('GUBRA_act_output_Dan_Excel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the module to ask to the user if they want to print and additional data frame with selected columns\n",
    "# all_columns = density.columns.values\n",
    "# possible_columns = np.delete(all_columns, np.where(all_columns == 'raw'))\n",
    "# possible_columns = np.delete(possible_columns, np.where(possible_columns == 'd_nickname'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33  Files processed \n",
      " \n",
      " Execution time: 74404.84 seconds\n"
     ]
    }
   ],
   "source": [
    "#Ending timming process\n",
    "end = time.time()\n",
    "\n",
    "# Printing how many files were processed and how much time the process took\n",
    "files_processed = number_activity_files = number_files+ number_volume_files + number_volintissue_files\n",
    "print(files_processed,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
